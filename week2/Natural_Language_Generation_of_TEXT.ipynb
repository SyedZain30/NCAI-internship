{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Natural Language Generation of TEXT.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "IECgWL4bmehR"
      },
      "source": [
        "import numpy\n",
        "import sys\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMFZZQHQmnHB",
        "outputId": "81a9e911-457d-4189-c86b-7bd00c4d181e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXI2yHmymtNe"
      },
      "source": [
        "filename = \"/content/drive/MyDrive/Colab Notebooks/TUKL summer internship/week1/pg11.txt\"\n",
        "raw_text = open(filename, 'r', encoding='utf-8').read()\n",
        "raw_text = raw_text.lower()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSEs-m1znJP5"
      },
      "source": [
        "# create mapping of unique chars to integers\n",
        "chars = sorted(list(set(raw_text)))\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7x9CvynnLRT",
        "outputId": "9664b03d-b1b1-40a1-93b0-d71e6d4110a4"
      },
      "source": [
        "n_chars = len(raw_text)\n",
        "n_vocab = len(chars)\n",
        "print(\"Total Characters: \", n_chars)\n",
        "print(\"Total Vocab: \", n_vocab)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Characters:  163781\n",
            "Total Vocab:  59\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsHhykk5nUfo",
        "outputId": "b7c040e6-483d-4220-8539-b1386d221c91"
      },
      "source": [
        "# prepare the dataset of input to output pairs encoded as integers\n",
        "seq_length = 100\n",
        "dataX = []\n",
        "dataY = []\n",
        "for i in range(0, n_chars - seq_length, 1):\n",
        "\tseq_in = raw_text[i:i + seq_length]\n",
        "\tseq_out = raw_text[i + seq_length]\n",
        "\tdataX.append([char_to_int[char] for char in seq_in])\n",
        "\tdataY.append(char_to_int[seq_out])\n",
        "n_patterns = len(dataX)\n",
        "print(\"Total Patterns: \", n_patterns)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Patterns:  163681\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTWqZz69nfrF"
      },
      "source": [
        "# reshape X to be [samples, time steps, features]\n",
        "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
        "# normalize\n",
        "X = X / float(n_vocab)\n",
        "# one hot encode the output variable\n",
        "y = np_utils.to_categorical(dataY)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cLUZX4Unk9n"
      },
      "source": [
        "# define the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMaO77bonqAB"
      },
      "source": [
        " #define the checkpoint\n",
        "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0wgBRWXnr78",
        "outputId": "5a915f6e-3f59-4efe-a92e-6b6eaaf38887"
      },
      "source": [
        "model.fit(X, y, epochs=20, batch_size=128, callbacks=callbacks_list)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1279/1279 [==============================] - 39s 14ms/step - loss: 3.0768\n",
            "\n",
            "Epoch 00001: loss improved from inf to 2.98374, saving model to weights-improvement-01-2.9837.hdf5\n",
            "Epoch 2/20\n",
            "1279/1279 [==============================] - 18s 14ms/step - loss: 2.8357\n",
            "\n",
            "Epoch 00002: loss improved from 2.98374 to 2.80501, saving model to weights-improvement-02-2.8050.hdf5\n",
            "Epoch 3/20\n",
            "1279/1279 [==============================] - 18s 14ms/step - loss: 2.7280\n",
            "\n",
            "Epoch 00003: loss improved from 2.80501 to 2.71232, saving model to weights-improvement-03-2.7123.hdf5\n",
            "Epoch 4/20\n",
            "1279/1279 [==============================] - 18s 14ms/step - loss: 2.6543\n",
            "\n",
            "Epoch 00004: loss improved from 2.71232 to 2.64213, saving model to weights-improvement-04-2.6421.hdf5\n",
            "Epoch 5/20\n",
            "1279/1279 [==============================] - 19s 15ms/step - loss: 2.5953\n",
            "\n",
            "Epoch 00005: loss improved from 2.64213 to 2.58932, saving model to weights-improvement-05-2.5893.hdf5\n",
            "Epoch 6/20\n",
            "1279/1279 [==============================] - 19s 15ms/step - loss: 2.5442\n",
            "\n",
            "Epoch 00006: loss improved from 2.58932 to 2.53660, saving model to weights-improvement-06-2.5366.hdf5\n",
            "Epoch 7/20\n",
            "1279/1279 [==============================] - 19s 15ms/step - loss: 2.4962\n",
            "\n",
            "Epoch 00007: loss improved from 2.53660 to 2.48912, saving model to weights-improvement-07-2.4891.hdf5\n",
            "Epoch 8/20\n",
            "1279/1279 [==============================] - 18s 14ms/step - loss: 2.4480\n",
            "\n",
            "Epoch 00008: loss improved from 2.48912 to 2.44576, saving model to weights-improvement-08-2.4458.hdf5\n",
            "Epoch 9/20\n",
            "1279/1279 [==============================] - 18s 14ms/step - loss: 2.4121\n",
            "\n",
            "Epoch 00009: loss improved from 2.44576 to 2.40713, saving model to weights-improvement-09-2.4071.hdf5\n",
            "Epoch 10/20\n",
            "1279/1279 [==============================] - 19s 15ms/step - loss: 2.3684\n",
            "\n",
            "Epoch 00010: loss improved from 2.40713 to 2.36768, saving model to weights-improvement-10-2.3677.hdf5\n",
            "Epoch 11/20\n",
            "1279/1279 [==============================] - 19s 15ms/step - loss: 2.3355\n",
            "\n",
            "Epoch 00011: loss improved from 2.36768 to 2.33082, saving model to weights-improvement-11-2.3308.hdf5\n",
            "Epoch 12/20\n",
            "1279/1279 [==============================] - 18s 14ms/step - loss: 2.2969\n",
            "\n",
            "Epoch 00012: loss improved from 2.33082 to 2.29801, saving model to weights-improvement-12-2.2980.hdf5\n",
            "Epoch 13/20\n",
            "1279/1279 [==============================] - 18s 14ms/step - loss: 2.2670\n",
            "\n",
            "Epoch 00013: loss improved from 2.29801 to 2.26651, saving model to weights-improvement-13-2.2665.hdf5\n",
            "Epoch 14/20\n",
            "1279/1279 [==============================] - 19s 15ms/step - loss: 2.2297\n",
            "\n",
            "Epoch 00014: loss improved from 2.26651 to 2.23399, saving model to weights-improvement-14-2.2340.hdf5\n",
            "Epoch 15/20\n",
            "1279/1279 [==============================] - 18s 14ms/step - loss: 2.1962\n",
            "\n",
            "Epoch 00015: loss improved from 2.23399 to 2.20179, saving model to weights-improvement-15-2.2018.hdf5\n",
            "Epoch 16/20\n",
            "1279/1279 [==============================] - 19s 14ms/step - loss: 2.1609\n",
            "\n",
            "Epoch 00016: loss improved from 2.20179 to 2.17135, saving model to weights-improvement-16-2.1714.hdf5\n",
            "Epoch 17/20\n",
            "1279/1279 [==============================] - 19s 15ms/step - loss: 2.1428\n",
            "\n",
            "Epoch 00017: loss improved from 2.17135 to 2.14707, saving model to weights-improvement-17-2.1471.hdf5\n",
            "Epoch 18/20\n",
            "1279/1279 [==============================] - 19s 15ms/step - loss: 2.1197\n",
            "\n",
            "Epoch 00018: loss improved from 2.14707 to 2.12150, saving model to weights-improvement-18-2.1215.hdf5\n",
            "Epoch 19/20\n",
            "1279/1279 [==============================] - 19s 15ms/step - loss: 2.0837\n",
            "\n",
            "Epoch 00019: loss improved from 2.12150 to 2.09462, saving model to weights-improvement-19-2.0946.hdf5\n",
            "Epoch 20/20\n",
            "1279/1279 [==============================] - 19s 15ms/step - loss: 2.0640\n",
            "\n",
            "Epoch 00020: loss improved from 2.09462 to 2.07195, saving model to weights-improvement-20-2.0720.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fba70440950>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fr0U0Aklnwlz"
      },
      "source": [
        "# load the network weights\n",
        "filename = \"/content/weights-improvement-20-2.0720.hdf5\"\n",
        "model.load_weights(filename)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTWuxZUdpWwQ"
      },
      "source": [
        "int_to_char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OeTY2pVtpx9S",
        "outputId": "f9fe2ab8-ce05-4c0a-f250-ac3ee23a10b8"
      },
      "source": [
        "# pick a random seed\n",
        "start = numpy.random.randint(0, len(dataX)-1)\n",
        "pattern = dataX[start]\n",
        "print(\"Seed:\")\n",
        "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
        "# generate characters\n",
        "for i in range(1000):\n",
        "\tx = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "\tx = x / float(n_vocab)\n",
        "\tprediction = model.predict(x, verbose=0)\n",
        "\tindex = numpy.argmax(prediction)\n",
        "\tresult = int_to_char[index]\n",
        "\tseq_in = [int_to_char[value] for value in pattern]\n",
        "\tsys.stdout.write(result)\n",
        "\tpattern.append(index)\n",
        "\tpattern = pattern[1:len(pattern)]\n",
        "print(\"\\nDone.\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seed:\n",
            "\" \n",
            "here the queen put on her spectacles, and began staring at the hatter,\n",
            "who turned pale and fidgeted \"\n",
            " an the could, \n",
            "and the whrt hn the care an the could so the thate whs oo whth the sooe. and the whit hn sae soted an anl, and she wordd har ine toiee an the could, and saed to the kure and the was oot in tie toiee  and the whrt ho the moote so the toies oo the toils. \n",
            "\n",
            "the word  she pooe turtle harden an the could, and saed to the kure and the wordd hard oe the crrre of the tar oo the toiee  and toe teit to tee the gorse if thetee an the corse. \n",
            "\n",
            "the word  she pooe turtle harden an the cade  and the whrt hn the care thth a lore fno ano an the cadl, and the white was a lintle toiee of the car, and then the woide of the carc th tene the car  she woile toine oo the toils oo the toids. \n",
            "\n",
            "''bhdpee tiit il whe horse sf the tae--                               *    *    *    *    *    *    *    *    *    *    *    *    *    *    *    *    *    *    *    *    *    *    *    *    *    *    *    *    *    *    *    *    *    *    *    *    *    *    *    *    *    *    *    *    *    *    *    *\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0KvMcsxpzbf"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(256))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCLGvokyqVgt",
        "outputId": "d29ec15e-3768-47d3-c7fd-bedb079c8765"
      },
      "source": [
        "model.fit(X, y, epochs=50, batch_size=64)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "2558/2558 [==============================] - 52s 19ms/step - loss: 2.9644\n",
            "Epoch 2/50\n",
            "2558/2558 [==============================] - 49s 19ms/step - loss: 2.5831\n",
            "Epoch 3/50\n",
            "2558/2558 [==============================] - 49s 19ms/step - loss: 2.3740\n",
            "Epoch 4/50\n",
            "2558/2558 [==============================] - 49s 19ms/step - loss: 2.2067\n",
            "Epoch 5/50\n",
            "2558/2558 [==============================] - 49s 19ms/step - loss: 2.0928\n",
            "Epoch 6/50\n",
            "2558/2558 [==============================] - 49s 19ms/step - loss: 2.0094\n",
            "Epoch 7/50\n",
            "2558/2558 [==============================] - 49s 19ms/step - loss: 1.9278\n",
            "Epoch 8/50\n",
            "2558/2558 [==============================] - 49s 19ms/step - loss: 1.8663\n",
            "Epoch 9/50\n",
            "2558/2558 [==============================] - 49s 19ms/step - loss: 1.8165\n",
            "Epoch 10/50\n",
            "2558/2558 [==============================] - 49s 19ms/step - loss: 1.7741\n",
            "Epoch 11/50\n",
            "2558/2558 [==============================] - 49s 19ms/step - loss: 1.7325\n",
            "Epoch 12/50\n",
            "2558/2558 [==============================] - 49s 19ms/step - loss: 1.6913\n",
            "Epoch 13/50\n",
            "2558/2558 [==============================] - 49s 19ms/step - loss: 1.6638\n",
            "Epoch 14/50\n",
            "2558/2558 [==============================] - 49s 19ms/step - loss: 1.6326\n",
            "Epoch 15/50\n",
            "2558/2558 [==============================] - 49s 19ms/step - loss: 1.6046\n",
            "Epoch 16/50\n",
            "2558/2558 [==============================] - 49s 19ms/step - loss: 1.5728\n",
            "Epoch 17/50\n",
            "2558/2558 [==============================] - 49s 19ms/step - loss: 1.5521\n",
            "Epoch 18/50\n",
            "2558/2558 [==============================] - 49s 19ms/step - loss: 1.5345\n",
            "Epoch 19/50\n",
            "2558/2558 [==============================] - 49s 19ms/step - loss: 1.5086\n",
            "Epoch 20/50\n",
            "2558/2558 [==============================] - 49s 19ms/step - loss: 1.4911\n",
            "Epoch 21/50\n",
            "2558/2558 [==============================] - 49s 19ms/step - loss: 1.4763\n",
            "Epoch 22/50\n",
            "2558/2558 [==============================] - 49s 19ms/step - loss: 1.4575\n",
            "Epoch 23/50\n",
            "2558/2558 [==============================] - 49s 19ms/step - loss: 1.4444\n",
            "Epoch 24/50\n",
            "2558/2558 [==============================] - 49s 19ms/step - loss: 1.4340\n",
            "Epoch 25/50\n",
            "2558/2558 [==============================] - 49s 19ms/step - loss: 1.4202\n",
            "Epoch 26/50\n",
            "2558/2558 [==============================] - 49s 19ms/step - loss: 1.4079\n",
            "Epoch 27/50\n",
            "2558/2558 [==============================] - 49s 19ms/step - loss: 1.3931\n",
            "Epoch 28/50\n",
            "2558/2558 [==============================] - 49s 19ms/step - loss: 1.3849\n",
            "Epoch 29/50\n",
            "2558/2558 [==============================] - 49s 19ms/step - loss: 1.3675\n",
            "Epoch 30/50\n",
            "2558/2558 [==============================] - 49s 19ms/step - loss: 1.3617\n",
            "Epoch 31/50\n",
            "2558/2558 [==============================] - 49s 19ms/step - loss: 1.3584\n",
            "Epoch 32/50\n",
            "2558/2558 [==============================] - 49s 19ms/step - loss: 1.3512\n",
            "Epoch 33/50\n",
            "2558/2558 [==============================] - 49s 19ms/step - loss: 1.3396\n",
            "Epoch 34/50\n",
            "2558/2558 [==============================] - 49s 19ms/step - loss: 1.3428\n",
            "Epoch 35/50\n",
            "2558/2558 [==============================] - 49s 19ms/step - loss: 1.3327\n",
            "Epoch 36/50\n",
            "2558/2558 [==============================] - 49s 19ms/step - loss: 1.3205\n",
            "Epoch 37/50\n",
            "2558/2558 [==============================] - 50s 19ms/step - loss: 1.3158\n",
            "Epoch 38/50\n",
            "2558/2558 [==============================] - 49s 19ms/step - loss: 1.3084\n",
            "Epoch 39/50\n",
            "2558/2558 [==============================] - 49s 19ms/step - loss: 1.3107\n",
            "Epoch 40/50\n",
            "2558/2558 [==============================] - 49s 19ms/step - loss: 1.3009\n",
            "Epoch 41/50\n",
            "2558/2558 [==============================] - 50s 19ms/step - loss: 1.3104\n",
            "Epoch 42/50\n",
            "2558/2558 [==============================] - 49s 19ms/step - loss: 1.2902\n",
            "Epoch 43/50\n",
            "2558/2558 [==============================] - 49s 19ms/step - loss: 1.2825\n",
            "Epoch 44/50\n",
            "2558/2558 [==============================] - 49s 19ms/step - loss: 1.2921\n",
            "Epoch 45/50\n",
            "2558/2558 [==============================] - 49s 19ms/step - loss: 1.2811\n",
            "Epoch 46/50\n",
            "2558/2558 [==============================] - 49s 19ms/step - loss: 1.2869\n",
            "Epoch 47/50\n",
            "2558/2558 [==============================] - 49s 19ms/step - loss: 1.2918\n",
            "Epoch 48/50\n",
            "2558/2558 [==============================] - 49s 19ms/step - loss: 1.2707\n",
            "Epoch 49/50\n",
            "2558/2558 [==============================] - 49s 19ms/step - loss: 1.2748\n",
            "Epoch 50/50\n",
            "2558/2558 [==============================] - 49s 19ms/step - loss: 1.2716\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fba29527a10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UU81LLddqbXk"
      },
      "source": [
        "int_to_char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gn_nfhtMrPAl",
        "outputId": "a0fa2d32-3c90-4e11-aca0-c7175d2939e1"
      },
      "source": [
        "# pick a random seed\n",
        "start = numpy.random.randint(0, len(dataX)-1)\n",
        "pattern = dataX[start]\n",
        "print(\"Seed:\")\n",
        "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
        "# generate characters\n",
        "for i in range(1000):\n",
        "\tx = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "\tx = x / float(n_vocab)\n",
        "\tprediction = model.predict(x, verbose=0)\n",
        "\tindex = numpy.argmax(prediction)\n",
        "\tresult = int_to_char[index]\n",
        "\tseq_in = [int_to_char[value] for value in pattern]\n",
        "\tsys.stdout.write(result)\n",
        "\tpattern.append(index)\n",
        "\tpattern = pattern[1:len(pattern)]\n",
        "print(\"\\nDone.\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seed:\n",
            "\" ),\n",
            "and sometimes she scolded herself so severely as to bring tears into\n",
            "her eyes; and once she remem \"\n",
            "bered herself up to the door and see that had gallen into a little bertat one of the lort of the shope. \n",
            "'it was a very curious beau? i shink you'd better not ' said the mouse, and the gatter was variing the table to the sueen side of the roof, \n",
            "'i dan tell you the bane uas that ' said the mouse, and the gatter was a little shriek, and said to herself, 'i must be gatd to the sea. they're doesn't be a little thing!'\n",
            "\n",
            "'i dan't ae a vall ' said the mouse, and the gatter was a little shriek, and said, 'if you don't know what they're a catcu?' she said to herself, 'i must be gatd to the sea- the doomouse was she was oot of the same againtt the door the way of the ooeert of the soees of the same and a little breatures of the coor, and she was going to be lost that they could be a little bertat some at the cook had and become the sabbit was an incoudd, and the door and she was now and tereaming to her fead off the sood of the soog. \n",
            "'i dan't ge mseh had you the bane uith it was,' said the moc\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScS3Ka5rrS0U"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}